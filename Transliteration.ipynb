{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transliteration.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP72wFd4JHYw5U+FGWP1N/Q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZEO4QQe3VB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiGffEDf3Y33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BehZIiLp3ghE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download = drive.CreateFile({'id': '1h1bnxUksOgasexvz3IFdIWZbwPPklIOq'})\n",
        "download.GetContentFile('test.xml')\n",
        "download = drive.CreateFile({'id': '1eha4iSfIK41Im9Kacd32l3c0ZxxJjClX'})\n",
        "download.GetContentFile('train.xml')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-9LzntezhCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "350db7cd-9fbb-4e78-91e7-9ceae527e9c5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-PneheE1W0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "84727864-121e-4b06-8c5a-0d281e7e6409"
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHinfmyp1dTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "95a15e49-e795-4e5c-dc80-dcf59f68fcc6"
      },
      "source": [
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnRLuJJs1f5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z2ijERX1ls_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHnR__Qi1t6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "dd53dbe5-52d9-42c2-913c-bf2048cb960d"
      },
      "source": [
        "train_data = TransliterationDataLoader('train.xml')\n",
        "test_data = TransliterationDataLoader('test.xml')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeJkoKfC2Ksb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "74b42105-8633-4043-fe29-736fc4926402"
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(hindi + ' - ' + eng)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "WYK - वीक\n",
            "E - ए\n",
            "PUBLIC - पब्लिक\n",
            "PARIVARTAN - परिवर्तन\n",
            "ARTHUR - आर्थर\n",
            "FURT - फ़र्ट\n",
            "PARAVEJ - परवेज\n",
            "HURLEY - हरले\n",
            "HUMAYDAH - हुमयदाह\n",
            "SYSTEMS - सिस्टम्स\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFyYhSmv2R45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxW0_jdx4jlZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "47805937-284a-4fa3-a667-47eb74bfdd5c"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "hindi_rep = word_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_rep)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "का tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm8-oDR44_km",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b6ebcb3a-30a5-4f2d-b685-a78d74f6472f"
      },
      "source": [
        "eng_gt = gt_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_gt)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KA tensor([[11],\n",
            "        [ 1],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DsZCr8N5j0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gJVtWwS7aAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if type(m) in [nn.Linear, nn.Conv2d, nn.Conv1d]:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0.01)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S4O_x0K535Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(hindi_alpha2index), 256, len(eng_alpha2index), verbose=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFNOXiXr59lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(net, word, max_op_chars,device='cpu'):\n",
        "  out = net.forward(word_rep(word, hindi_alpha2index), max_output_chars=max_op_chars,device=device)\n",
        "  return out"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3trpAZV6Efp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d4f47426-7a09-430a-f1ad-2c55e8f77904"
      },
      "source": [
        "out = infer(net, 'आर्थर', 30)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 27])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 27])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObSHwxMD6OZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "8382e507-9b86-4186-a863-20c381c308f7"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(eng_alpha2index.keys())[list(eng_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n",
            "torch.Size([1, 27]) D\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn8IFyPo6kMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    hindi_batch, eng_batch = train_data.get_batch(batch_size)\n",
        "    # print(eng_batch, hindi_batch)\n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        gt = gt_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hscHB6fU7CIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu',file_name='model.pt'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    # lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, verbose=True, patience=100)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        epoch_loss = train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto )\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + epoch_loss)/(i + 1)\n",
        "        # lr_scheduler.step(epoch_loss)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, file_name)\n",
        "    return loss_arr"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d_ysY_57zwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 4000\n",
        "lr = 0.001\n",
        "weight_decay = 1e-5\n",
        "clip_norm = 5"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvZ4jiEa7344",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DirQtpOk7EpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "5de54233-de16-4978-afe7-3ced59986a3d"
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder(len(hindi_alpha2index), 256, len(eng_alpha2index))\n",
        "net_att.apply(weights_init)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transliteration_EncoderDecoder(\n",
              "  (encoder_rnn_cell): GRU(129, 256)\n",
              "  (decoder_rnn_cell): GRU(512, 256)\n",
              "  (h2o): Linear(in_features=256, out_features=27, bias=True)\n",
              "  (softmax): LogSoftmax(dim=2)\n",
              "  (U): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (W): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (attn): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (out2hidden): Linear(in_features=27, out_features=256, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8M795ZT7R0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "1af0d186-a947-4d15-8756-a8482b2d3804"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=lr, n_batches=num_epochs, batch_size = 16, display_freq=5, device = device_gpu,file_name='transliteration.pt')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 3999 Loss 0.35505786538124084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwaWG1ALTXUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(eng, eng_alpha2index, device)\n",
        "        outputs = infer(net, hindi, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            eng_pos = indices.tolist()[0]\n",
        "            if eng_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giuwWv9vTbPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_new(net, word, device = 'cpu'):\n",
        "    net=net.eval().to(device)\n",
        "    print(hindi_alphabets)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    eng_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        print(index)\n",
        "        if index == 0:\n",
        "            break\n",
        "        eng_char = eng_alphabets[index-1]\n",
        "        print(eng_char)\n",
        "        eng_output += eng_char\n",
        "    print(word + ' - ' + eng_output)\n",
        "    return eng_output\n",
        "    # return outputs"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3L96FT7TYXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c30a87a1-1ed4-48bc-b746-f364d21381b4"
      },
      "source": [
        "\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurracy with attention 72.6721256358022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4NPOc2oTx2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "c0367b1c-b62a-4cab-a99f-32b8170b0be3"
      },
      "source": [
        "test_new(net_att,'आर्थर')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ', 'ॿ']\n",
            "1\n",
            "A\n",
            "18\n",
            "R\n",
            "20\n",
            "T\n",
            "8\n",
            "H\n",
            "8\n",
            "H\n",
            "18\n",
            "R\n",
            "18\n",
            "R\n",
            "0\n",
            "आर्थर - ARTHHRR\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ARTHHRR'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iDMVYylkKhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}